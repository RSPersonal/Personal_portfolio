from functools import lru_cache
<<<<<<< HEAD
from typing import List, Optional

from .constant import COMMON_SAFE_ASCII_CHARACTERS, UNICODE_SECONDARY_RANGE_KEYWORD
from .utils import (
    is_accentuated,
    is_ascii,
    is_case_variable,
    is_cjk,
    is_emoticon,
    is_hangul,
    is_hiragana,
    is_katakana,
    is_latin,
    is_punctuation,
    is_separator,
    is_symbol,
    is_thai,
    remove_accent,
    unicode_range,
)
=======
from typing import Optional, List

from charset_normalizer.constant import UNICODE_SECONDARY_RANGE_KEYWORD
from charset_normalizer.utils import is_punctuation, is_symbol, unicode_range, is_accentuated, is_latin, \
    remove_accent, is_separator, is_cjk, is_case_variable, is_hangul, is_katakana, is_hiragana, is_ascii, is_thai
>>>>>>> origin/heroku-prod-build


class MessDetectorPlugin:
    """
    Base abstract class used for mess detection plugins.
    All detectors MUST extend and implement given methods.
    """

    def eligible(self, character: str) -> bool:
        """
        Determine if given character should be fed in.
        """
        raise NotImplementedError  # pragma: nocover

    def feed(self, character: str) -> None:
        """
        The main routine to be executed upon character.
        Insert the logic in witch the text would be considered chaotic.
        """
        raise NotImplementedError  # pragma: nocover

<<<<<<< HEAD
    def reset(self) -> None:  # pragma: no cover
        """
        Permit to reset the plugin to the initial state.
        """
        raise NotImplementedError
=======
    def reset(self) -> None:
        """
        Permit to reset the plugin to the initial state.
        """
        raise NotImplementedError  # pragma: nocover
>>>>>>> origin/heroku-prod-build

    @property
    def ratio(self) -> float:
        """
        Compute the chaos ratio based on what your feed() has seen.
        Must NOT be lower than 0.; No restriction gt 0.
        """
        raise NotImplementedError  # pragma: nocover


class TooManySymbolOrPunctuationPlugin(MessDetectorPlugin):
<<<<<<< HEAD
    def __init__(self) -> None:
=======

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._punctuation_count = 0  # type: int
        self._symbol_count = 0  # type: int
        self._character_count = 0  # type: int

        self._last_printable_char = None  # type: Optional[str]
        self._frenzy_symbol_in_word = False  # type: bool

    def eligible(self, character: str) -> bool:
        return character.isprintable()

    def feed(self, character: str) -> None:
        self._character_count += 1

<<<<<<< HEAD
        if (
            character != self._last_printable_char
            and character not in COMMON_SAFE_ASCII_CHARACTERS
        ):
            if is_punctuation(character):
                self._punctuation_count += 1
            elif (
                character.isdigit() is False
                and is_symbol(character)
                and is_emoticon(character) is False
            ):
=======
        if character != self._last_printable_char and character not in ["<", ">", "=", ":", "/", "&", ";", "{", "}", "[", "]", ",", "|", '"']:
            if is_punctuation(character):
                self._punctuation_count += 1
            elif character.isdigit() is False and is_symbol(character):
>>>>>>> origin/heroku-prod-build
                self._symbol_count += 2

        self._last_printable_char = character

<<<<<<< HEAD
    def reset(self) -> None:  # pragma: no cover
=======
    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._punctuation_count = 0
        self._character_count = 0
        self._symbol_count = 0

    @property
    def ratio(self) -> float:
        if self._character_count == 0:
<<<<<<< HEAD
            return 0.0

        ratio_of_punctuation = (
            self._punctuation_count + self._symbol_count
        ) / self._character_count  # type: float

        return ratio_of_punctuation if ratio_of_punctuation >= 0.3 else 0.0


class TooManyAccentuatedPlugin(MessDetectorPlugin):
    def __init__(self) -> None:
=======
            return 0.

        ratio_of_punctuation = (self._punctuation_count + self._symbol_count) / self._character_count  # type: float

        return ratio_of_punctuation if ratio_of_punctuation >= 0.3 else 0.


class TooManyAccentuatedPlugin(MessDetectorPlugin):

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._character_count = 0  # type: int
        self._accentuated_count = 0  # type: int

    def eligible(self, character: str) -> bool:
        return character.isalpha()

    def feed(self, character: str) -> None:
        self._character_count += 1

        if is_accentuated(character):
            self._accentuated_count += 1

<<<<<<< HEAD
    def reset(self) -> None:  # pragma: no cover
=======
    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._character_count = 0
        self._accentuated_count = 0

    @property
    def ratio(self) -> float:
        if self._character_count == 0:
<<<<<<< HEAD
            return 0.0
        ratio_of_accentuation = (
            self._accentuated_count / self._character_count
        )  # type: float
        return ratio_of_accentuation if ratio_of_accentuation >= 0.35 else 0.0


class UnprintablePlugin(MessDetectorPlugin):
    def __init__(self) -> None:
=======
            return 0.
        ratio_of_accentuation = self._accentuated_count / self._character_count  # type: float
        return ratio_of_accentuation if ratio_of_accentuation >= 0.35 else 0.


class UnprintablePlugin(MessDetectorPlugin):

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._unprintable_count = 0  # type: int
        self._character_count = 0  # type: int

    def eligible(self, character: str) -> bool:
        return True

    def feed(self, character: str) -> None:
<<<<<<< HEAD
        if (
            character.isspace() is False  # includes \n \t \r \v
            and character.isprintable() is False
            and character != "\x1A"  # Why? Its the ASCII substitute character.
        ):
            self._unprintable_count += 1
        self._character_count += 1

    def reset(self) -> None:  # pragma: no cover
=======
        if character not in {'\n', '\t', '\r', '\v'} and character.isprintable() is False:
            self._unprintable_count += 1
        self._character_count += 1

    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._unprintable_count = 0

    @property
    def ratio(self) -> float:
        if self._character_count == 0:
<<<<<<< HEAD
            return 0.0
=======
            return 0.
>>>>>>> origin/heroku-prod-build

        return (self._unprintable_count * 8) / self._character_count


class SuspiciousDuplicateAccentPlugin(MessDetectorPlugin):
<<<<<<< HEAD
    def __init__(self) -> None:
=======

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._successive_count = 0  # type: int
        self._character_count = 0  # type: int

        self._last_latin_character = None  # type: Optional[str]

    def eligible(self, character: str) -> bool:
        return character.isalpha() and is_latin(character)

    def feed(self, character: str) -> None:
        self._character_count += 1
<<<<<<< HEAD
        if (
            self._last_latin_character is not None
            and is_accentuated(character)
            and is_accentuated(self._last_latin_character)
        ):
            if character.isupper() and self._last_latin_character.isupper():
                self._successive_count += 1
            # Worse if its the same char duplicated with different accent.
            if remove_accent(character) == remove_accent(self._last_latin_character):
                self._successive_count += 1
        self._last_latin_character = character

    def reset(self) -> None:  # pragma: no cover
=======
        if self._last_latin_character is not None:
            if is_accentuated(character) and is_accentuated(self._last_latin_character):
                if character.isupper() and self._last_latin_character.isupper():
                    self._successive_count += 1
                # Worse if its the same char duplicated with different accent.
                if remove_accent(character) == remove_accent(self._last_latin_character):
                    self._successive_count += 1
        self._last_latin_character = character

    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._successive_count = 0
        self._character_count = 0
        self._last_latin_character = None

    @property
    def ratio(self) -> float:
        if self._character_count == 0:
<<<<<<< HEAD
            return 0.0
=======
            return 0.
>>>>>>> origin/heroku-prod-build

        return (self._successive_count * 2) / self._character_count


class SuspiciousRange(MessDetectorPlugin):
<<<<<<< HEAD
    def __init__(self) -> None:
=======

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._suspicious_successive_range_count = 0  # type: int
        self._character_count = 0  # type: int
        self._last_printable_seen = None  # type: Optional[str]

    def eligible(self, character: str) -> bool:
        return character.isprintable()

    def feed(self, character: str) -> None:
        self._character_count += 1

<<<<<<< HEAD
        if (
            character.isspace()
            or is_punctuation(character)
            or character in COMMON_SAFE_ASCII_CHARACTERS
        ):
=======
        if character.isspace() or is_punctuation(character):
>>>>>>> origin/heroku-prod-build
            self._last_printable_seen = None
            return

        if self._last_printable_seen is None:
            self._last_printable_seen = character
            return

<<<<<<< HEAD
        unicode_range_a = unicode_range(
            self._last_printable_seen
        )  # type: Optional[str]
=======
        unicode_range_a = unicode_range(self._last_printable_seen)  # type: Optional[str]
>>>>>>> origin/heroku-prod-build
        unicode_range_b = unicode_range(character)  # type: Optional[str]

        if is_suspiciously_successive_range(unicode_range_a, unicode_range_b):
            self._suspicious_successive_range_count += 1

        self._last_printable_seen = character

<<<<<<< HEAD
    def reset(self) -> None:  # pragma: no cover
=======
    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._character_count = 0
        self._suspicious_successive_range_count = 0
        self._last_printable_seen = None

    @property
    def ratio(self) -> float:
        if self._character_count == 0:
<<<<<<< HEAD
            return 0.0

        ratio_of_suspicious_range_usage = (
            self._suspicious_successive_range_count * 2
        ) / self._character_count  # type: float

        if ratio_of_suspicious_range_usage < 0.1:
            return 0.0
=======
            return 0.

        ratio_of_suspicious_range_usage = (self._suspicious_successive_range_count * 2) / self._character_count  # type: float

        if ratio_of_suspicious_range_usage < 0.1:
            return 0.
>>>>>>> origin/heroku-prod-build

        return ratio_of_suspicious_range_usage


class SuperWeirdWordPlugin(MessDetectorPlugin):
<<<<<<< HEAD
    def __init__(self) -> None:
        self._word_count = 0  # type: int
        self._bad_word_count = 0  # type: int
        self._foreign_long_count = 0  # type: int

=======

    def __init__(self):
        self._word_count = 0  # type: int
        self._bad_word_count = 0  # type: int
>>>>>>> origin/heroku-prod-build
        self._is_current_word_bad = False  # type: bool
        self._foreign_long_watch = False  # type: bool

        self._character_count = 0  # type: int
        self._bad_character_count = 0  # type: int

        self._buffer = ""  # type: str
        self._buffer_accent_count = 0  # type: int

    def eligible(self, character: str) -> bool:
        return True

    def feed(self, character: str) -> None:
        if character.isalpha():
            self._buffer = "".join([self._buffer, character])
            if is_accentuated(character):
                self._buffer_accent_count += 1
<<<<<<< HEAD
            if (
                self._foreign_long_watch is False
                and (is_latin(character) is False or is_accentuated(character))
                and is_cjk(character) is False
                and is_hangul(character) is False
                and is_katakana(character) is False
                and is_hiragana(character) is False
                and is_thai(character) is False
            ):
=======
            if self._foreign_long_watch is False and is_latin(character) is False and is_cjk(character) is False and is_hangul(character) is False and is_katakana(character) is False and is_hiragana(character) is False and is_thai(character) is False:
>>>>>>> origin/heroku-prod-build
                self._foreign_long_watch = True
            return
        if not self._buffer:
            return
<<<<<<< HEAD
        if (
            character.isspace() or is_punctuation(character) or is_separator(character)
        ) and self._buffer:
=======
        if (character.isspace() or is_punctuation(character) or is_separator(character)) and self._buffer:
>>>>>>> origin/heroku-prod-build
            self._word_count += 1
            buffer_length = len(self._buffer)  # type: int

            self._character_count += buffer_length

<<<<<<< HEAD
            if buffer_length >= 4:
                if self._buffer_accent_count / buffer_length > 0.34:
                    self._is_current_word_bad = True
                # Word/Buffer ending with a upper case accentuated letter are so rare,
                # that we will consider them all as suspicious. Same weight as foreign_long suspicious.
                if is_accentuated(self._buffer[-1]) and self._buffer[-1].isupper():
                    self._foreign_long_count += 1
                    self._is_current_word_bad = True
            if buffer_length >= 24 and self._foreign_long_watch:
                self._foreign_long_count += 1
=======
            if buffer_length >= 4 and self._buffer_accent_count / buffer_length >= 0.3:
                self._is_current_word_bad = True
            if buffer_length >= 24 and self._foreign_long_watch:
>>>>>>> origin/heroku-prod-build
                self._is_current_word_bad = True

            if self._is_current_word_bad:
                self._bad_word_count += 1
                self._bad_character_count += len(self._buffer)
                self._is_current_word_bad = False

            self._foreign_long_watch = False
            self._buffer = ""
            self._buffer_accent_count = 0
<<<<<<< HEAD
        elif (
            character not in {"<", ">", "-", "="}
            and character.isdigit() is False
            and is_symbol(character)
        ):
            self._is_current_word_bad = True
            self._buffer += character

    def reset(self) -> None:  # pragma: no cover
=======
        elif character not in {"<", ">", "-", "="} and character.isdigit() is False and is_symbol(character):
            self._is_current_word_bad = True
            self._buffer += character

    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._buffer = ""
        self._is_current_word_bad = False
        self._foreign_long_watch = False
        self._bad_word_count = 0
        self._word_count = 0
        self._character_count = 0
        self._bad_character_count = 0
<<<<<<< HEAD
        self._foreign_long_count = 0

    @property
    def ratio(self) -> float:
        if self._word_count <= 10 and self._foreign_long_count == 0:
            return 0.0
=======

    @property
    def ratio(self) -> float:
        if self._word_count <= 10:
            return 0.
>>>>>>> origin/heroku-prod-build

        return self._bad_character_count / self._character_count


class CjkInvalidStopPlugin(MessDetectorPlugin):
    """
<<<<<<< HEAD
    GB(Chinese) based encoding often render the stop incorrectly when the content does not fit and
    can be easily detected. Searching for the overuse of '丅' and '丄'.
    """

    def __init__(self) -> None:
=======
    GB(Chinese) based encoding often render the stop incorrectly when the content does not fit and can be easily detected.
    Searching for the overuse of '丅' and '丄'.
    """

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._wrong_stop_count = 0  # type: int
        self._cjk_character_count = 0  # type: int

    def eligible(self, character: str) -> bool:
        return True

    def feed(self, character: str) -> None:
<<<<<<< HEAD
        if character in {"丅", "丄"}:
=======
        if character in ["丅", "丄"]:
>>>>>>> origin/heroku-prod-build
            self._wrong_stop_count += 1
            return
        if is_cjk(character):
            self._cjk_character_count += 1

<<<<<<< HEAD
    def reset(self) -> None:  # pragma: no cover
=======
    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._wrong_stop_count = 0
        self._cjk_character_count = 0

    @property
    def ratio(self) -> float:
        if self._cjk_character_count < 16:
<<<<<<< HEAD
            return 0.0
=======
            return 0.
>>>>>>> origin/heroku-prod-build
        return self._wrong_stop_count / self._cjk_character_count


class ArchaicUpperLowerPlugin(MessDetectorPlugin):
<<<<<<< HEAD
    def __init__(self) -> None:
=======

    def __init__(self):
>>>>>>> origin/heroku-prod-build
        self._buf = False  # type: bool

        self._character_count_since_last_sep = 0  # type: int

        self._successive_upper_lower_count = 0  # type: int
        self._successive_upper_lower_count_final = 0  # type: int

        self._character_count = 0  # type: int

        self._last_alpha_seen = None  # type: Optional[str]
        self._current_ascii_only = True  # type: bool

    def eligible(self, character: str) -> bool:
        return True

    def feed(self, character: str) -> None:
        is_concerned = character.isalpha() and is_case_variable(character)
        chunk_sep = is_concerned is False

        if chunk_sep and self._character_count_since_last_sep > 0:
<<<<<<< HEAD
            if (
                self._character_count_since_last_sep <= 64
                and character.isdigit() is False
                and self._current_ascii_only is False
            ):
                self._successive_upper_lower_count_final += (
                    self._successive_upper_lower_count
                )
=======
            if self._character_count_since_last_sep <= 64 and character.isdigit() is False and self._current_ascii_only is False:
                self._successive_upper_lower_count_final += self._successive_upper_lower_count
>>>>>>> origin/heroku-prod-build

            self._successive_upper_lower_count = 0
            self._character_count_since_last_sep = 0
            self._last_alpha_seen = None
            self._buf = False
            self._character_count += 1
            self._current_ascii_only = True

            return

        if self._current_ascii_only is True and is_ascii(character) is False:
            self._current_ascii_only = False

        if self._last_alpha_seen is not None:
<<<<<<< HEAD
            if (character.isupper() and self._last_alpha_seen.islower()) or (
                character.islower() and self._last_alpha_seen.isupper()
            ):
=======
            if (character.isupper() and self._last_alpha_seen.islower()) or (character.islower() and self._last_alpha_seen.isupper()):
>>>>>>> origin/heroku-prod-build
                if self._buf is True:
                    self._successive_upper_lower_count += 2
                    self._buf = False
                else:
                    self._buf = True
            else:
                self._buf = False

        self._character_count += 1
        self._character_count_since_last_sep += 1
        self._last_alpha_seen = character

<<<<<<< HEAD
    def reset(self) -> None:  # pragma: no cover
=======
    def reset(self) -> None:
>>>>>>> origin/heroku-prod-build
        self._character_count = 0
        self._character_count_since_last_sep = 0
        self._successive_upper_lower_count = 0
        self._successive_upper_lower_count_final = 0
        self._last_alpha_seen = None
        self._buf = False
        self._current_ascii_only = True

    @property
    def ratio(self) -> float:
        if self._character_count == 0:
<<<<<<< HEAD
            return 0.0
=======
            return 0.
>>>>>>> origin/heroku-prod-build

        return self._successive_upper_lower_count_final / self._character_count


<<<<<<< HEAD
def is_suspiciously_successive_range(
    unicode_range_a: Optional[str], unicode_range_b: Optional[str]
) -> bool:
=======
def is_suspiciously_successive_range(unicode_range_a: Optional[str], unicode_range_b: Optional[str]) -> bool:
>>>>>>> origin/heroku-prod-build
    """
    Determine if two Unicode range seen next to each other can be considered as suspicious.
    """
    if unicode_range_a is None or unicode_range_b is None:
        return True

    if unicode_range_a == unicode_range_b:
        return False

    if "Latin" in unicode_range_a and "Latin" in unicode_range_b:
        return False

    if "Emoticons" in unicode_range_a or "Emoticons" in unicode_range_b:
        return False

<<<<<<< HEAD
    # Latin characters can be accompanied with a combining diacritical mark
    # eg. Vietnamese.
    if ("Latin" in unicode_range_a or "Latin" in unicode_range_b) and (
        "Combining" in unicode_range_a or "Combining" in unicode_range_b
    ):
        return False

    keywords_range_a, keywords_range_b = unicode_range_a.split(
        " "
    ), unicode_range_b.split(" ")
=======
    keywords_range_a, keywords_range_b = unicode_range_a.split(" "), unicode_range_b.split(" ")
>>>>>>> origin/heroku-prod-build

    for el in keywords_range_a:
        if el in UNICODE_SECONDARY_RANGE_KEYWORD:
            continue
        if el in keywords_range_b:
            return False

    # Japanese Exception
<<<<<<< HEAD
    range_a_jp_chars, range_b_jp_chars = (
        unicode_range_a
        in (
            "Hiragana",
            "Katakana",
        ),
        unicode_range_b in ("Hiragana", "Katakana"),
    )
    if (range_a_jp_chars or range_b_jp_chars) and (
        "CJK" in unicode_range_a or "CJK" in unicode_range_b
    ):
        return False
    if range_a_jp_chars and range_b_jp_chars:
        return False

=======
    if unicode_range_a in ['Katakana', 'Hiragana'] and unicode_range_b in ['Katakana', 'Hiragana']:
        return False

    if unicode_range_a in ['Katakana', 'Hiragana'] or unicode_range_b in ['Katakana', 'Hiragana']:
        if "CJK" in unicode_range_a or "CJK" in unicode_range_b:
            return False

>>>>>>> origin/heroku-prod-build
    if "Hangul" in unicode_range_a or "Hangul" in unicode_range_b:
        if "CJK" in unicode_range_a or "CJK" in unicode_range_b:
            return False
        if unicode_range_a == "Basic Latin" or unicode_range_b == "Basic Latin":
            return False

    # Chinese/Japanese use dedicated range for punctuation and/or separators.
<<<<<<< HEAD
    if ("CJK" in unicode_range_a or "CJK" in unicode_range_b) or (
        unicode_range_a in ["Katakana", "Hiragana"]
        and unicode_range_b in ["Katakana", "Hiragana"]
    ):
        if "Punctuation" in unicode_range_a or "Punctuation" in unicode_range_b:
            return False
        if "Forms" in unicode_range_a or "Forms" in unicode_range_b:
=======
    if ('CJK' in unicode_range_a or 'CJK' in unicode_range_b) or (unicode_range_a in ['Katakana', 'Hiragana'] and unicode_range_b in ['Katakana', 'Hiragana']):
        if 'Punctuation' in unicode_range_a or 'Punctuation' in unicode_range_b:
            return False
        if 'Forms' in unicode_range_a or 'Forms' in unicode_range_b:
>>>>>>> origin/heroku-prod-build
            return False

    return True


@lru_cache(maxsize=2048)
<<<<<<< HEAD
def mess_ratio(
    decoded_sequence: str, maximum_threshold: float = 0.2, debug: bool = False
) -> float:
    """
    Compute a mess ratio given a decoded bytes sequence. The maximum threshold does stop the computation earlier.
    """

    detectors = [
        md_class() for md_class in MessDetectorPlugin.__subclasses__()
    ]  # type: List[MessDetectorPlugin]

    length = len(decoded_sequence) + 1  # type: int

    mean_mess_ratio = 0.0  # type: float
=======
def mess_ratio(decoded_sequence: str, maximum_threshold: float = 0.2, debug: bool = False) -> float:
    """
    Compute a mess ratio given a decoded bytes sequence. The maximum threshold does stop the computation earlier.
    """
    detectors = []  # type: List[MessDetectorPlugin]

    for md_class in MessDetectorPlugin.__subclasses__():
        detectors.append(
            md_class()
        )

    length = len(decoded_sequence)  # type: int

    mean_mess_ratio = 0.  # type: float
>>>>>>> origin/heroku-prod-build

    if length < 512:
        intermediary_mean_mess_ratio_calc = 32  # type: int
    elif length <= 1024:
        intermediary_mean_mess_ratio_calc = 64
    else:
        intermediary_mean_mess_ratio_calc = 128

<<<<<<< HEAD
    for character, index in zip(decoded_sequence + "\n", range(length)):
=======
    for character, index in zip(decoded_sequence, range(0, length)):
>>>>>>> origin/heroku-prod-build
        for detector in detectors:
            if detector.eligible(character):
                detector.feed(character)

<<<<<<< HEAD
        if (
            index > 0 and index % intermediary_mean_mess_ratio_calc == 0
        ) or index == length - 1:
            mean_mess_ratio = sum(dt.ratio for dt in detectors)
=======
        if (index > 0 and index % intermediary_mean_mess_ratio_calc == 0) or index == length-1:
            mean_mess_ratio = sum(
                [
                    dt.ratio for dt in detectors
                ]
            )
>>>>>>> origin/heroku-prod-build

            if mean_mess_ratio >= maximum_threshold:
                break

    if debug:
        for dt in detectors:  # pragma: nocover
<<<<<<< HEAD
            print(dt.__class__, dt.ratio)

    return round(mean_mess_ratio, 3)
=======
            print(
                dt.__class__,
                dt.ratio
            )

    return round(
        mean_mess_ratio,
        3
    )

>>>>>>> origin/heroku-prod-build
